{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pylab \n",
    "import scipy.stats as stats\n",
    "\n",
    "from scipy.stats import skew\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global Setting\n",
    "\n",
    "\n",
    "# Rand Seed\n",
    "RandSeed0 = 123;\n",
    "\n",
    "\n",
    "# Set the threshold for being over-skewed\n",
    "# (can tune later)\n",
    "skew0 = 0.6;\n",
    "\n",
    "\n",
    "#-----------------------------------------------------\n",
    "\n",
    "# Setting of Flags\n",
    "\n",
    "# For Section 1: \n",
    "# Data Loading ----------------------------------------\n",
    "#whichDataSet = 0;\n",
    "whichDataSet = 'w';\n",
    "\n",
    "# For Section 2: \n",
    "# Data Pre-Processing ---------------------------------\n",
    "use_2_CookedUp_Features = 1;\n",
    "# Use Bath/Bed and Garage/Bed or not\n",
    "# 1 means Yes; other numbers mean No. \n",
    "\n",
    "use_2_CookedUp_Features_instead = 0;\n",
    "# Use Bath/Bed and Garage/Bed instead of Bath (Full, Half), Garage\n",
    "# 1 means Yes; other numbers mean No. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test mega dataset shape: (2919, 72)\n"
     ]
    }
   ],
   "source": [
    "if whichDataSet == 0: # Using the original data set \n",
    "    train = pd.read_csv('Datasets/train.csv')\n",
    "    test = pd.read_csv('Datasets/test.csv')\n",
    "    # Concat. train[no ID column, ... (all columns) ..., no SalePrice column]\n",
    "    #     with test[no ID column, ... (all columns) ..., no SalePrice column]\n",
    "    # (Test data has no SalePrice column anyway)\n",
    "    train_test = pd.concat([train.loc[:,'MSSubClass':'SaleCondition'],\n",
    "                             test.loc[:,'MSSubClass':'SaleCondition']]);\n",
    "    print('Train-Test mega dataset shape:',train_test.shape)\n",
    "##\n",
    "##\n",
    "if whichDataSet == 'w': # Using Wenchang's modified data set\n",
    "    train = pd.read_csv('Datasets/train_Wenchang.csv')\n",
    "    test = pd.read_csv('Datasets/test_Wenchang.csv')\n",
    "    train.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    test.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    train_test = pd.concat([train.loc[:,'1stFlrSF':'RemodYearDiff'],\n",
    "                             test.loc[:,'1stFlrSF':'RemodYearDiff']]);\n",
    "    print('Train-Test mega dataset shape:',train_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pre-Processing\n",
    "* 2.0 (Optional) Add Cooked_up Features: Bath_Capacity and Parking_Capacity\n",
    "* 2.1 Some Preliminary Examination and Symmetrization\n",
    "* 2.2 Fill in NAs\n",
    "* 2.3 Encode Categorical Features\n",
    "* 2.4 Set up training and test data matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 (Optional) Add Cooked_up Features: Bath_Capacitance and Parking_Capacitance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_2_CookedUp_Features == 1:\n",
    "    #\n",
    "    # Compute Total Bathrooms in a house\n",
    "    # and set those with zero bathroom with median bathroom number\n",
    "    train['TotBath'] = train.FullBath + 0.5*train.HalfBath;\n",
    "    test['TotBath'] = test.FullBath + 0.5*test.HalfBath;\n",
    "    train_test['TotBath'] = train_test.FullBath + 0.5*train_test.HalfBath;\n",
    "    #\n",
    "    train['TotBath'].replace(0, train['TotBath'].median(), inplace=True);\n",
    "    test['TotBath'].replace(0, test['TotBath'].median(), inplace=True);\n",
    "    train_test['TotBath'].replace(0, train_test['TotBath'].median(), inplace=True);\n",
    "    #------------------------------------------------------------------------------\n",
    "    #\n",
    "    # Set those with zero bedroom with median bedfroom number \n",
    "    # (or set them to one to be conservative)\n",
    "    train['BedroomAbvGr'].replace(0, train['BedroomAbvGr'].median(), inplace=True);\n",
    "    test['BedroomAbvGr'].replace(0, test['BedroomAbvGr'].median(), inplace=True);\n",
    "    train_test['BedroomAbvGr'].replace(0, train_test['BedroomAbvGr'].median(), inplace=True);\n",
    "    #------------------------------------------------------------------------------\n",
    "    #\n",
    "    # Cook-up Feature 1:\n",
    "    # Bath_Capacitance = TotBath / BedroomAbvGr\n",
    "    train['Bath_Capacitance'] = train.TotBath / train.BedroomAbvGr\n",
    "    test['Bath_Capacitance'] = train.TotBath / train.BedroomAbvGr\n",
    "    train_test['Bath_Capacitance'] = train.TotBath / train.BedroomAbvGr\n",
    "    #------------------------------------------------------------------------------\n",
    "    #\n",
    "    # Cook-up Feature 2: \n",
    "    # Parking_Capacitance = TotBath / BedroomAbvGr\n",
    "    train['Parking_Capacitance'] = train.GarageCars / train.BedroomAbvGr\n",
    "    test['Parking_Capacitance'] = train.GarageCars / train.BedroomAbvGr\n",
    "    train_test['Parking_Capacitance'] = train.GarageCars / train.BedroomAbvGr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_2_CookedUp_Features_instead == 1:\n",
    "    #\n",
    "    # Reasonable dropping ---------------------------------------- \n",
    "    #\n",
    "    train.drop(train[['FullBath', \n",
    "                      'HalfBath']], axis=1, inplace=True)\n",
    "    test.drop(test[['FullBath', \n",
    "                    'HalfBath']], axis=1, inplace=True)\n",
    "    train_test.drop(train_test[['FullBath', \n",
    "                                'HalfBath']], axis=1, inplace=True)\n",
    "    #\n",
    "    # Dropping that needs more scrutiny ---------------------------------------- \n",
    "    #\n",
    "    #train.drop(train[['TotBath']], axis=1, inplace=True)\n",
    "    #test.drop(test[['TotBath']], axis=1, inplace=True)\n",
    "    #train_test.drop(train_test[['TotBath']], axis=1, inplace=True)\n",
    "    # Dropping that needs more scrutiny ---------------------------------------- \n",
    "    #\n",
    "    #train.drop(train[['GarageCars']], axis=1, inplace=True)\n",
    "    #test.drop(test[['GarageCars']], axis=1, inplace=True)\n",
    "    #train_test.drop(train_test[['GarageCars']], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 (a) Preliminary Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As observed, symmetrize SalePrice via log(1 + ***)\n",
    "train.SalePrice = np.log(1 + train.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 (b) Symmetrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = train_test.dtypes[train_test.dtypes != \"object\"].index\n",
    "\n",
    "skewed_features = train[numeric_features].apply(lambda x: skew(x.dropna())) \n",
    "skewed_features = skewed_features[abs( skewed_features ) > skew0]\n",
    "skewed_features = skewed_features.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test[skewed_features] = np.log(1 + train_test[skewed_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Encode Categorical Features\n",
    "#### Using plain and simple one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test = pd.get_dummies(train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_test.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Fill in NAs\n",
    "\n",
    "#### Interpolating NAs with the median of each field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if whichDataSet == 0:\n",
    "    train_test = train_test.fillna(train_test.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Set up training and test data matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_test[:train.shape[0]]\n",
    "X_test  = train_test[train.shape[0]:]\n",
    "y_train = train.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Create Artificial Train-Test Data Sets via Train-Test-Split\n",
    "### For model validation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [X_train_v, X_test_v, y_train_v, y_test_v] \n",
    "# all come from the original [X_train, y_train] \n",
    "##\n",
    "## Naming convention: \n",
    "## The \"_v\" in names such as \"X_train_v\" is \n",
    "## to indicate such set is for validation purposes.\n",
    "\n",
    "X_train_v, X_test_v, y_train_v, y_test_v =\\\n",
    "    ms.train_test_split(deepcopy(X_train),\\\n",
    "                        deepcopy(y_train),\\\n",
    "                        test_size = 1/8,\\\n",
    "                        random_state = RandSeed0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling\n",
    "\n",
    "### 3.1 Linear Regression with Ridge Regularizations where $L(\\ \\vec{\\beta} \\ ) = MSE + \\alpha \\cdot \\frac{1}{2} ||\\ \\vec{\\beta}\\ ||_{L_{2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using the [X_train_v, y_train_v] to search for the optimal hyper-parameter(s)\n",
    "def rmse_cv(model):\n",
    "    rmse = np.sqrt( -cross_val_score(model, X_train_v, y_train_v, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)\n",
    "\n",
    "#def rmse(pdSeries0):\n",
    "#    # Specifically, pdSeries0 is a series of Residuals\n",
    "#    rmse = np.sqrt( sum(pdSeries0**2) / pdSeries0.size )\n",
    "#    return(rmse)\n",
    "\n",
    "# Use the built-in MSE calculator\n",
    "def rmse(y_predicted, y_actual):\n",
    "    return( np.sqrt( mean_squared_error(y_actual, y_predicted) ) )\n",
    "\n",
    "\n",
    "def R2(y_predicted, y_actual):\n",
    "    # R^2 = 1 - SS_residual / SS_total\n",
    "    SS_residual = sum((y_predicted - y_actual)**2)\n",
    "    SS_total = sum((y_actual - y_actual.mean())**2)\n",
    "    R2 = 1 - SS_residual / SS_total\n",
    "    return(R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# supply a log-ranged alphas from 10^(-2) to 10^(2)\n",
    "# total: 60 alphas to do CV\n",
    "alpha_array = np.logspace(-1,2,64)\n",
    "\n",
    "cv_Ridge = [rmse_cv(Ridge(alpha = Alpha)).mean() for Alpha in alpha_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_Ridge = pd.Series(cv_Ridge, index = alpha_array)\n",
    "\n",
    "alpha0 = cv_Ridge[cv_Ridge == cv_Ridge.min()].index[0];\n",
    "rmse0 = cv_Ridge.min();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model_Ridge = Ridge(alpha0).fit(X_train_v, y_train_v);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Ridge Training Performace: R^2 = 0.9233\n",
      "**************************************************\n",
      "Ridge Training Performace: RMSE = 0.1107\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Training Performance\n",
    "# The results are put in dataframe \"predictions_Ridge_train\"\n",
    "\n",
    "predictions_Ridge_train = pd.DataFrame({\"Predicted\":model_Ridge.predict(X_train_v), \n",
    "                                        \"Actual\":y_train_v});\n",
    "predictions_Ridge_train[\"Residual\"] = predictions_Ridge_train.Actual - predictions_Ridge_train.Predicted;\n",
    "\n",
    "R2_Ridge_train = model_Ridge.score(X_train_v, y_train_v);\n",
    "\n",
    "RMSE_Ridge_train = rmse(predictions_Ridge_train.Actual, predictions_Ridge_train.Predicted);\n",
    "\n",
    "print('*'*50)\n",
    "print('Ridge Training Performace: R^2 = {:.4f}'.format(R2_Ridge_train))\n",
    "print('*'*50)\n",
    "print('Ridge Training Performace: RMSE = {:.4f}'.format(RMSE_Ridge_train))\n",
    "print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Ridge Test Performace: R^2 = 0.9342\n",
      "**************************************************\n",
      "Ridge Test Performace: RMSE = 0.1006\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Test Performance\n",
    "# The results are put in dataframe \"predictions_Ridge_test\"\n",
    "\n",
    "predictions_Ridge_test = pd.DataFrame({\"Predicted\":model_Ridge.predict(X_test_v), \n",
    "                                       \"Actual\":y_test_v});\n",
    "predictions_Ridge_test[\"Residual\"] = predictions_Ridge_test.Actual - predictions_Ridge_test.Predicted;\n",
    "\n",
    "R2_Ridge_test = model_Ridge.score(X_test_v, y_test_v);\n",
    "\n",
    "RMSE_Ridge_test = rmse(predictions_Ridge_test.Actual, predictions_Ridge_test.Predicted);\n",
    "\n",
    "print('*'*50)\n",
    "print('Ridge Test Performace: R^2 = {:.4f}'.format(R2_Ridge_test))\n",
    "print('*'*50)\n",
    "print('Ridge Test Performace: RMSE = {:.4f}'.format(RMSE_Ridge_test))\n",
    "print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate Test Vector (Ridge)\n",
    "\n",
    "output_Ridge_test = model_Ridge.predict(X_test);\n",
    "\n",
    "# de-Logarithm\n",
    "output_Ridge_test = -1 + np.exp(output_Ridge_test); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(output_Ridge_test))\n",
    "\n",
    "#output_Ridge_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Try with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': [0.005, 0.01, 0.05, 0.1, 0.5], 'n_estimators': [50, 100, 200, 500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_paramters = {'learning_rate':[0.005, 0.01, 0.05, 0.1, 0.5],\n",
    "                 'n_estimators':[50, 100, 200, 500]}\n",
    "\n",
    "xgb_GridSearch = GridSearchCV(xgboost.XGBRegressor(), param_grid=xgb_paramters)\n",
    "\n",
    "xgb_GridSearch.fit(X_train_v, y_train_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate0 = xgb_GridSearch.best_params_['learning_rate'];\n",
    "n_estimators0 = xgb_GridSearch.best_params_['n_estimators'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89167840716541458"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xgb_GridSearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "xgboost.XGBRegressor(\n",
    "    max_depth=3, \n",
    "    learning_rate=0.1, \n",
    "    n_estimators=100, \n",
    "    silent=True, \n",
    "    objective='reg:linear', \n",
    "    booster='gbtree', \n",
    "    n_jobs=1, \n",
    "    nthread=None, \n",
    "    gamma=0, \n",
    "    min_child_weight=1, \n",
    "    max_delta_step=0, \n",
    "    subsample=1, \n",
    "    colsample_bytree=1, \n",
    "    colsample_bylevel=1, \n",
    "    reg_alpha=0, \n",
    "    reg_lambda=1, \n",
    "    scale_pos_weight=1, \n",
    "    base_score=0.5, \n",
    "    random_state=0, \n",
    "    seed=None, \n",
    "    missing=None, \n",
    "    **kwargs)\n",
    "'''\n",
    "\n",
    "\n",
    "model_xgb = xgboost.XGBRegressor(learning_rate=learning_rate0,\n",
    "                                 n_estimators=n_estimators0)\n",
    "\n",
    "model_xgb = model_xgb.fit(X_train_v, y_train_v);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "XGBooster Training Performace: R^2 = 0.9756\n",
      "**************************************************\n",
      "XGBooster Training Performace: RMSE = 0.0625\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Training Performance\n",
    "# The results are put in dataframe \"predictions_xgb_train\"\n",
    "\n",
    "predictions_xgb_train = pd.DataFrame({\"Predicted\":model_xgb.predict(X_train_v), \n",
    "                                      \"Actual\":y_train_v});\n",
    "predictions_xgb_train[\"Residual\"] = predictions_xgb_train.Actual - predictions_xgb_train.Predicted;\n",
    "\n",
    "R2_xgb_train = R2(predictions_xgb_train.Predicted, predictions_xgb_train.Actual);\n",
    "\n",
    "RMSE_xgb_train = rmse(predictions_xgb_train.Actual, predictions_xgb_train.Predicted);\n",
    "\n",
    "print('*'*50)\n",
    "print('XGBooster Training Performace: R^2 = {:.4f}'.format(R2_xgb_train))\n",
    "print('*'*50)\n",
    "print('XGBooster Training Performace: RMSE = {:.4f}'.format(RMSE_xgb_train))\n",
    "print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "XGBooster Test Performace: R^2 = 0.9245\n",
      "**************************************************\n",
      "XGBooster Test Performace: RMSE = 0.1077\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Test Performance\n",
    "# The results are put in dataframe \"predictions_xgb_test\"\n",
    "\n",
    "predictions_xgb_test = pd.DataFrame({\"Predicted\":model_xgb.predict(X_test_v), \n",
    "                                      \"Actual\":y_test_v});\n",
    "predictions_xgb_test[\"Residual\"] = predictions_xgb_test.Actual - predictions_xgb_test.Predicted;\n",
    "\n",
    "\n",
    "R2_xgb_test = R2(predictions_xgb_test.Predicted, predictions_xgb_test.Actual);\n",
    "\n",
    "RMSE_xgb_test = rmse(predictions_xgb_test.Actual, predictions_xgb_test.Predicted);\n",
    "\n",
    "print('*'*50)\n",
    "print('XGBooster Test Performace: R^2 = {:.4f}'.format(R2_xgb_test));\n",
    "print('*'*50)\n",
    "print('XGBooster Test Performace: RMSE = {:.4f}'.format(RMSE_xgb_test));\n",
    "print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate Test Vector (XGB)\n",
    "\n",
    "output_xgb_test = model_xgb.predict(X_test);\n",
    "\n",
    "# de-Logarithm\n",
    "output_xgb_test = -1 + np.exp(output_xgb_test); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 124052.9375   ,  159566.109375 ,  183471.59375  , ...,\n",
       "        157286.53125  ,  118197.6953125,  216752.734375 ], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(len(output_xgb_test))\n",
    "\n",
    "#output_xgb_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Final Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use RMSE or use RMSE_to_R2\n",
    "\n",
    "use_RMSE = 1;\n",
    "\n",
    "if use_RMSE == 1:\n",
    "    rho_Ridge = RMSE_Ridge_test;\n",
    "    rho_xgb = RMSE_xgb_test;\n",
    "    #rho_RForest = RMSE_RForest_test;\n",
    "else:\n",
    "    rho_Ridge = RMSE_Ridge_test / R2_Ridge_test;\n",
    "    rho_xgb = RMSE_xgb_test / R2_xgb_test;\n",
    "    #rho_RForest = RMSE_RForest_test / R2_RForest_test;\n",
    "    \n",
    "s = rho_Ridge + rho_xgb;\n",
    "\n",
    "w_Ridge = 1 - rho_Ridge / s;\n",
    "w_xgb = 1 - rho_xgb / s;\n",
    "\n",
    "output_final = 1/2 * (w_Ridge * output_Ridge_test + \n",
    "                      w_xgb * output_xgb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_Ridge + w_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
