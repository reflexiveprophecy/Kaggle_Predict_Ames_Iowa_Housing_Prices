{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global Setting\n",
    "\n",
    "\n",
    "# Rand Seed\n",
    "RandSeed0 = 123;\n",
    "\n",
    "\n",
    "# Set the threshold for being over-skewed\n",
    "# (can tune later)\n",
    "skew0 = 0.6;\n",
    "\n",
    "\n",
    "#-----------------------------------------------------\n",
    "\n",
    "# Setting of Flags\n",
    "\n",
    "# For Section 1: \n",
    "# Data Loading ----------------------------------------\n",
    "#whichDataSet = 0;\n",
    "whichDataSet = 'w';\n",
    "\n",
    "# For Section 2: \n",
    "# Data Pre-Processing ---------------------------------\n",
    "use_2_CookedUp_Features = 1;\n",
    "# Use Bath/Bed and Garage/Bed or not\n",
    "# 1 means Yes; other numbers mean No. \n",
    "\n",
    "use_2_CookedUp_Features_instead = 0;\n",
    "# Use Bath/Bed and Garage/Bed instead of Bath (Full, Half), Garage\n",
    "# 1 means Yes; other numbers mean No. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pylab \n",
    "import scipy.stats as stats\n",
    "\n",
    "from scipy.stats import skew\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import xgboost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test mega dataset shape: (2919, 72)\n"
     ]
    }
   ],
   "source": [
    "if whichDataSet == 0: # Using the original data set \n",
    "    train = pd.read_csv('Datasets/train.csv')\n",
    "    test = pd.read_csv('Datasets/test.csv')\n",
    "    # Concat. train[no ID column, ... (all columns) ..., no SalePrice column]\n",
    "    #     with test[no ID column, ... (all columns) ..., no SalePrice column]\n",
    "    # (Test data has no SalePrice column anyway)\n",
    "    train_test = pd.concat([train.loc[:,'MSSubClass':'SaleCondition'],\n",
    "                             test.loc[:,'MSSubClass':'SaleCondition']]);\n",
    "    print('Train-Test mega dataset shape:',train_test.shape)\n",
    "##\n",
    "##\n",
    "if whichDataSet == 'w': # Using Wenchang's modified data set\n",
    "    train = pd.read_csv('Datasets/train_Wenchang.csv')\n",
    "    test = pd.read_csv('Datasets/test_Wenchang.csv')\n",
    "    train.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    test.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    train_test = pd.concat([train.loc[:,'1stFlrSF':'RemodYearDiff'],\n",
    "                             test.loc[:,'1stFlrSF':'RemodYearDiff']]);\n",
    "    print('Train-Test mega dataset shape:',train_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pre-Processing\n",
    "* 2.0 (Optional) Add Cooked_up Features: Bath_Capacity and Parking_Capacity\n",
    "* 2.1 Some Preliminary Examination and Symmetrization\n",
    "* 2.2 Fill in NAs\n",
    "* 2.3 Encode Categorical Features\n",
    "* 2.4 Set up training and test data matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 (Optional) Add Cooked_up Features: Bath_Capacitance and Parking_Capacitance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_2_CookedUp_Features == 1:\n",
    "    #\n",
    "    # Compute Total Bathrooms in a house\n",
    "    # and set those with zero bathroom with median bathroom number\n",
    "    train['TotBath'] = train.FullBath + 0.5*train.HalfBath;\n",
    "    test['TotBath'] = test.FullBath + 0.5*test.HalfBath;\n",
    "    train_test['TotBath'] = train_test.FullBath + 0.5*train_test.HalfBath;\n",
    "    #\n",
    "    train['TotBath'].replace(0, train['TotBath'].median(), inplace=True);\n",
    "    test['TotBath'].replace(0, test['TotBath'].median(), inplace=True);\n",
    "    train_test['TotBath'].replace(0, train_test['TotBath'].median(), inplace=True);\n",
    "    #------------------------------------------------------------------------------\n",
    "    #\n",
    "    # Set those with zero bedroom with median bedfroom number \n",
    "    # (or set them to one to be conservative)\n",
    "    train['BedroomAbvGr'].replace(0, train['BedroomAbvGr'].median(), inplace=True);\n",
    "    test['BedroomAbvGr'].replace(0, test['BedroomAbvGr'].median(), inplace=True);\n",
    "    train_test['BedroomAbvGr'].replace(0, train_test['BedroomAbvGr'].median(), inplace=True);\n",
    "    #------------------------------------------------------------------------------\n",
    "    #\n",
    "    # Cook-up Feature 1:\n",
    "    # Bath_Capacitance = TotBath / BedroomAbvGr\n",
    "    train['Bath_Capacitance'] = train.TotBath / train.BedroomAbvGr\n",
    "    test['Bath_Capacitance'] = train.TotBath / train.BedroomAbvGr\n",
    "    train_test['Bath_Capacitance'] = train.TotBath / train.BedroomAbvGr\n",
    "    #------------------------------------------------------------------------------\n",
    "    #\n",
    "    # Cook-up Feature 2: \n",
    "    # Parking_Capacitance = TotBath / BedroomAbvGr\n",
    "    train['Parking_Capacitance'] = train.GarageCars / train.BedroomAbvGr\n",
    "    test['Parking_Capacitance'] = train.GarageCars / train.BedroomAbvGr\n",
    "    train_test['Parking_Capacitance'] = train.GarageCars / train.BedroomAbvGr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_2_CookedUp_Features_instead == 1:\n",
    "    #\n",
    "    # Reasonable dropping ---------------------------------------- \n",
    "    #\n",
    "    train.drop(train[['FullBath', \n",
    "                      'HalfBath']], axis=1, inplace=True)\n",
    "    test.drop(test[['FullBath', \n",
    "                    'HalfBath']], axis=1, inplace=True)\n",
    "    train_test.drop(train_test[['FullBath', \n",
    "                                'HalfBath']], axis=1, inplace=True)\n",
    "    #\n",
    "    # Dropping that needs more scrutiny ---------------------------------------- \n",
    "    #\n",
    "    #train.drop(train[['TotBath']], axis=1, inplace=True)\n",
    "    #test.drop(test[['TotBath']], axis=1, inplace=True)\n",
    "    #train_test.drop(train_test[['TotBath']], axis=1, inplace=True)\n",
    "    # Dropping that needs more scrutiny ---------------------------------------- \n",
    "    #\n",
    "    #train.drop(train[['GarageCars']], axis=1, inplace=True)\n",
    "    #test.drop(test[['GarageCars']], axis=1, inplace=True)\n",
    "    #train_test.drop(train_test[['GarageCars']], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 (a) Preliminary Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As observed, symmetrize SalePrice via log(1 + ***)\n",
    "train.SalePrice = np.log(1 + train.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 (b) Symmetrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_features = train_test.dtypes[train_test.dtypes != \"object\"].index\n",
    "\n",
    "skewed_features = train[numeric_features].apply(lambda x: skew(x.dropna())) \n",
    "skewed_features = skewed_features[abs( skewed_features ) > skew0]\n",
    "skewed_features = skewed_features.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test[skewed_features] = np.log(1 + train_test[skewed_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Encode Categorical Features\n",
    "#### Using plain and simple one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test = pd.get_dummies(train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_test.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Fill in NAs\n",
    "\n",
    "#### Interpolating NAs with the median of each field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if whichDataSet == 0:\n",
    "    train_test = train_test.fillna(train_test.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Set up training and test data matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_test[:train.shape[0]]\n",
    "X_test  = train_test[train.shape[0]:]\n",
    "y_train = train.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Create Artificial Train-Test Data Sets via Train-Test-Split\n",
    "### For model validation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [X_train_v, X_test_v, y_train_v, y_test_v] \n",
    "# all come from the original [X_train, y_train] \n",
    "##\n",
    "## Naming convention: \n",
    "## The \"_v\" in names such as \"X_train_v\" is \n",
    "## to indicate such set is for validation purposes.\n",
    "\n",
    "X_train_v, X_test_v, y_train_v, y_test_v =\\\n",
    "    ms.train_test_split(deepcopy(X_train),\\\n",
    "                        deepcopy(y_train),\\\n",
    "                        test_size = 1/8,\\\n",
    "                        random_state = RandSeed0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using the [X_train_v, y_train_v] to search for the optimal hyper-parameter(s)\n",
    "def rmse_cv(model):\n",
    "    rmse = np.sqrt( -cross_val_score(model, X_train_v, y_train_v, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)\n",
    "\n",
    "#def rmse(pdSeries0):\n",
    "#    # Specifically, pdSeries0 is a series of Residuals\n",
    "#    rmse = np.sqrt( sum(pdSeries0**2) / pdSeries0.size )\n",
    "#    return(rmse)\n",
    "\n",
    "# Use the built-in MSE calculator\n",
    "def rmse(y_predicted, y_actual):\n",
    "    return( np.sqrt( mean_squared_error(y_actual, y_predicted) ) )\n",
    "\n",
    "\n",
    "def R2(y_predicted, y_actual):\n",
    "    # R^2 = 1 - SS_residual / SS_total\n",
    "    SS_residual = sum((y_predicted - y_actual)**2)\n",
    "    SS_total = sum((y_actual - y_actual.mean())**2)\n",
    "    R2 = 1 - SS_residual / SS_total\n",
    "    return(R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Linear Regression with Ridge Regularizations where $L(\\ \\vec{\\beta} \\ ) = MSE + \\alpha \\cdot \\frac{1}{2} ||\\ \\vec{\\beta}\\ ||_{L_{2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Ridge Training Performace: R^2 = 0.9233\n",
      "**************************************************\n",
      "Ridge Training Performace: RMSE = 0.1107\n",
      "**************************************************\n",
      "**************************************************\n",
      "Ridge Test Performace: R^2 = 0.9342\n",
      "**************************************************\n",
      "Ridge Test Performace: RMSE = 0.1006\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# supply a log-ranged alphas from 10^(-2) to 10^(2)\n",
    "# total: 60 alphas to do CV\n",
    "alpha_array = np.logspace(-1,2,64)\n",
    "\n",
    "cv_Ridge = [rmse_cv(Ridge(alpha = Alpha)).mean() for Alpha in alpha_array]\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "cv_Ridge = pd.Series(cv_Ridge, index = alpha_array)\n",
    "\n",
    "alpha0_Ridge = cv_Ridge[cv_Ridge == cv_Ridge.min()].index[0];\n",
    "rmse0 = cv_Ridge.min();\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Training the model\n",
    "model_Ridge = Ridge(alpha0_Ridge).fit(X_train_v, y_train_v);\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Training Performance\n",
    "# The results are put in dataframe \"predictions_Ridge_train\"\n",
    "\n",
    "predictions_Ridge_train = pd.DataFrame({\"Predicted\":model_Ridge.predict(X_train_v), \n",
    "                                        \"Actual\":y_train_v});\n",
    "predictions_Ridge_train[\"Residual\"] = predictions_Ridge_train.Actual - predictions_Ridge_train.Predicted;\n",
    "\n",
    "R2_Ridge_train = model_Ridge.score(X_train_v, y_train_v);\n",
    "\n",
    "RMSE_Ridge_train = rmse(predictions_Ridge_train.Actual, predictions_Ridge_train.Predicted);\n",
    "\n",
    "print('*'*50)\n",
    "print('Ridge Training Performace: R^2 = {:.4f}'.format(R2_Ridge_train))\n",
    "print('*'*50)\n",
    "print('Ridge Training Performace: RMSE = {:.4f}'.format(RMSE_Ridge_train))\n",
    "print('*'*50)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Test Performance\n",
    "# The results are put in dataframe \"predictions_Ridge_test\"\n",
    "\n",
    "predictions_Ridge_test = pd.DataFrame({\"Predicted\":model_Ridge.predict(X_test_v), \n",
    "                                       \"Actual\":y_test_v});\n",
    "predictions_Ridge_test[\"Residual\"] = predictions_Ridge_test.Actual - predictions_Ridge_test.Predicted;\n",
    "\n",
    "R2_Ridge_test = model_Ridge.score(X_test_v, y_test_v);\n",
    "\n",
    "RMSE_Ridge_test = rmse(predictions_Ridge_test.Actual, predictions_Ridge_test.Predicted);\n",
    "\n",
    "print('*'*50)\n",
    "print('Ridge Test Performace: R^2 = {:.4f}'.format(R2_Ridge_test))\n",
    "print('*'*50)\n",
    "print('Ridge Test Performace: RMSE = {:.4f}'.format(RMSE_Ridge_test))\n",
    "print('*'*50)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Generate Test Vector (Ridge)\n",
    "\n",
    "output_Ridge_test = model_Ridge.predict(X_test);\n",
    "\n",
    "# de-Logarithm\n",
    "output_Ridge_test = -1 + np.exp(output_Ridge_test); \n",
    "\n",
    "#print(len(output_Ridge_test))\n",
    "\n",
    "#output_Ridge_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "XGBooster Training Performace: R^2 = 0.9756\n",
      "**************************************************\n",
      "XGBooster Training Performace: RMSE = 0.0625\n",
      "**************************************************\n",
      "**************************************************\n",
      "XGBooster Test Performace: R^2 = 0.9245\n",
      "**************************************************\n",
      "XGBooster Test Performace: RMSE = 0.1077\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "xgb_paramters = {'learning_rate':[0.005, 0.01, 0.05, 0.1, 0.5],\n",
    "                 'n_estimators':[50, 100, 200, 500]}\n",
    "\n",
    "xgb_GridSearch = GridSearchCV(xgboost.XGBRegressor(), param_grid=xgb_paramters)\n",
    "\n",
    "xgb_GridSearch.fit(X_train_v, y_train_v)\n",
    "\n",
    "#xgb_GridSearch.best_score_\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "learning_rate0_xgb = xgb_GridSearch.best_params_['learning_rate'];\n",
    "n_estimators0_xgb = xgb_GridSearch.best_params_['n_estimators'];\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "'''\n",
    "xgboost.XGBRegressor(\n",
    "    max_depth=3, \n",
    "    learning_rate=0.1, \n",
    "    n_estimators=100, \n",
    "    silent=True, \n",
    "    objective='reg:linear', \n",
    "    booster='gbtree', \n",
    "    n_jobs=1, \n",
    "    nthread=None, \n",
    "    gamma=0, \n",
    "    min_child_weight=1, \n",
    "    max_delta_step=0, \n",
    "    subsample=1, \n",
    "    colsample_bytree=1, \n",
    "    colsample_bylevel=1, \n",
    "    reg_alpha=0, \n",
    "    reg_lambda=1, \n",
    "    scale_pos_weight=1, \n",
    "    base_score=0.5, \n",
    "    random_state=0, \n",
    "    seed=None, \n",
    "    missing=None, \n",
    "    **kwargs)\n",
    "'''\n",
    "\n",
    "\n",
    "model_xgb = xgboost.XGBRegressor(learning_rate=learning_rate0_xgb,\n",
    "                                 n_estimators=n_estimators0_xgb)\n",
    "\n",
    "model_xgb = model_xgb.fit(X_train_v, y_train_v);\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Training Performance\n",
    "# The results are put in dataframe \"predictions_xgb_train\"\n",
    "\n",
    "predictions_xgb_train = pd.DataFrame({\"Predicted\":model_xgb.predict(X_train_v), \n",
    "                                      \"Actual\":y_train_v});\n",
    "predictions_xgb_train[\"Residual\"] = predictions_xgb_train.Actual - predictions_xgb_train.Predicted;\n",
    "\n",
    "R2_xgb_train = R2(predictions_xgb_train.Predicted, predictions_xgb_train.Actual);\n",
    "\n",
    "RMSE_xgb_train = rmse(predictions_xgb_train.Actual, predictions_xgb_train.Predicted);\n",
    "\n",
    "print('*'*50)\n",
    "print('XGBooster Training Performace: R^2 = {:.4f}'.format(R2_xgb_train))\n",
    "print('*'*50)\n",
    "print('XGBooster Training Performace: RMSE = {:.4f}'.format(RMSE_xgb_train))\n",
    "print('*'*50)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Test Performance\n",
    "# The results are put in dataframe \"predictions_xgb_test\"\n",
    "\n",
    "predictions_xgb_test = pd.DataFrame({\"Predicted\":model_xgb.predict(X_test_v), \n",
    "                                      \"Actual\":y_test_v});\n",
    "predictions_xgb_test[\"Residual\"] = predictions_xgb_test.Actual - predictions_xgb_test.Predicted;\n",
    "\n",
    "\n",
    "R2_xgb_test = R2(predictions_xgb_test.Predicted, predictions_xgb_test.Actual);\n",
    "\n",
    "RMSE_xgb_test = rmse(predictions_xgb_test.Actual, predictions_xgb_test.Predicted);\n",
    "\n",
    "print('*'*50)\n",
    "print('XGBooster Test Performace: R^2 = {:.4f}'.format(R2_xgb_test));\n",
    "print('*'*50)\n",
    "print('XGBooster Test Performace: RMSE = {:.4f}'.format(RMSE_xgb_test));\n",
    "print('*'*50)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Generate Test Vector (XGB)\n",
    "\n",
    "output_xgb_test = model_xgb.predict(X_test);\n",
    "\n",
    "# de-Logarithm\n",
    "output_xgb_test = -1 + np.exp(output_xgb_test); \n",
    "\n",
    "#print(len(output_xgb_test))\n",
    "\n",
    "#output_xgb_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Random Forest Training Performace: R^2 = 0.9830\n",
      "**************************************************\n",
      "Random Forest Training Performace: RMSE = 0.0521\n",
      "**************************************************\n",
      "**************************************************\n",
      "Random Forest Test Performace: R^2 = 0.9830\n",
      "**************************************************\n",
      "Random Forest Test Performace: RMSE = 0.1289\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import math\n",
    "\n",
    "rf_tree_cv = RandomForestRegressor(\n",
    "                                bootstrap = True,\n",
    "                                oob_score = True,\n",
    "                                random_state = 0)\n",
    "\n",
    "rf_param_grid = [{\n",
    "        'n_estimators' : [300, 400, 500, 600], #Test[100,250,500,750,1000]\n",
    "        'max_features' : np.arange(35,38), # First try: np.arange(17,40)\n",
    "}]\n",
    "\n",
    "rf_grid_search = GridSearchCV(rf_tree_cv, param_grid = rf_param_grid, cv = 5);\n",
    "\n",
    "rf_grid_search.fit(X_train_v, y_train_v);\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "max_features0_RForest = rf_grid_search.best_params_['max_features'];\n",
    "n_estimators0_RForest = rf_grid_search.best_params_['n_estimators'];\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "rf_tree = RandomForestRegressor(n_estimators = n_estimators0_RForest,\n",
    "                                max_features = max_features0_RForest,\n",
    "                                bootstrap = True,\n",
    "                                oob_score = True,\n",
    "                                random_state = 0)\n",
    "\n",
    "rf_tree.fit(X_train_v, y_train_v)\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "R2_RForest_train = rf_tree.score(X_train_v, y_train_v);\n",
    "\n",
    "RMSE_RForest_train = np.sqrt(mean_squared_error(y_train_v, rf_tree.predict(X_train_v)));\n",
    "\n",
    "print('*'*50)\n",
    "print('Random Forest Training Performace: R^2 = {:.4f}'.format(R2_RForest_train))\n",
    "print('*'*50)\n",
    "print('Random Forest Training Performace: RMSE = {:.4f}'.format(RMSE_RForest_train))\n",
    "print('*'*50)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "R2_RForest_test = rf_tree.score(X_train_v, y_train_v);\n",
    "\n",
    "RMSE_RForest_test = np.sqrt(mean_squared_error(y_test_v, rf_tree.predict(X_test_v)));\n",
    "\n",
    "print('*'*50)\n",
    "print('Random Forest Test Performace: R^2 = {:.4f}'.format(R2_RForest_test))\n",
    "print('*'*50)\n",
    "print('Random Forest Test Performace: RMSE = {:.4f}'.format(RMSE_RForest_test))\n",
    "print('*'*50)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "output_RForest_test = -1 + np.exp(rf_tree.predict(X_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use RMSE or use RMSE_to_R2\n",
    "\n",
    "use_RMSE = 1;\n",
    "\n",
    "if use_RMSE == 1:\n",
    "    rho_Ridge = RMSE_Ridge_test;\n",
    "    rho_xgb = RMSE_xgb_test;\n",
    "    rho_RForest = RMSE_RForest_test;\n",
    "else:\n",
    "    rho_Ridge = RMSE_Ridge_test / R2_Ridge_test;\n",
    "    rho_xgb = RMSE_xgb_test / R2_xgb_test;\n",
    "    rho_RForest = RMSE_RForest_test / R2_RForest_test;\n",
    "    \n",
    "s = rho_Ridge + rho_xgb + rho_RForest;\n",
    "\n",
    "w_Ridge = 1 - rho_Ridge / s;\n",
    "w_xgb = 1 - rho_xgb / s;\n",
    "w_RForest = 1 - rho_RForest / s;\n",
    "\n",
    "output_final_test = 1/2 * (w_Ridge * output_Ridge_test + \n",
    "                           w_xgb * output_xgb_test + \n",
    "                           w_RForest * output_RForest_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Weight for Ridge Prediction:0.3509\n",
      "**************************************************\n",
      "Weight for XGB Prediction:0.3403\n",
      "**************************************************\n",
      "Weight for Random Forest Prediction:0.3088\n",
      "**************************************************\n",
      "Final Predicted Sale Prices:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 122265.07116874,  159067.5080107 ,  181619.546485  , ...,\n",
       "        160930.39419413,  115241.58346796,  219001.39810577])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('*'*50)\n",
    "print('Weight for Ridge Prediction:{:.4f}'.format(w_Ridge/2))\n",
    "print('*'*50)\n",
    "print('Weight for XGB Prediction:{:.4f}'.format(w_xgb/2))\n",
    "print('*'*50)\n",
    "print('Weight for Random Forest Prediction:{:.4f}'.format(w_RForest/2))\n",
    "print('*'*50)\n",
    "\n",
    "print('Final Predicted Sale Prices:')\n",
    "output_final_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generate CSV File for Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Predictions_for_Kaggle = pd.read_csv('Datasets/test.csv');\n",
    "Predictions_for_Kaggle['SalePrice'] = output_final_test;\n",
    "Predictions_for_Kaggle = Predictions_for_Kaggle[['Id','SalePrice']];\n",
    "\n",
    "Predictions_for_Kaggle.head()\n",
    "\n",
    "Predictions_for_Kaggle.to_csv('Predictions_by_ProximaCentuari.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>122265.071169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>159067.508011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>181619.546485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>189681.921827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>193900.000467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  122265.071169\n",
       "1  1462  159067.508011\n",
       "2  1463  181619.546485\n",
       "3  1464  189681.921827\n",
       "4  1465  193900.000467"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check wheather the CSV file is properly saved and ready for submission\n",
    "\n",
    "pd.read_csv('Predictions_by_ProximaCentuari.csv').head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
